{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a621ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "\n",
    "# Authors: Robert Luke <mail@robertluke.net>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "# Import common libraries\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from itertools import compress\n",
    "from pprint import pprint\n",
    "\n",
    "# Import Plotting Library\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pywt\n",
    "import mne_nirs\n",
    "import mne\n",
    "\n",
    "\n",
    "\n",
    "# Import StatsModels\n",
    "import statsmodels.formula.api as smf\n",
    "from mne import Epochs, events_from_annotations, set_log_level\n",
    "from mne.preprocessing.nirs import (\n",
    "    beer_lambert_law,\n",
    "    optical_density,\n",
    "    scalp_coupling_index,\n",
    "    temporal_derivative_distribution_repair,\n",
    "    \n",
    ")\n",
    "\n",
    "# Import MNE processing\n",
    "from mne.viz import plot_compare_evokeds\n",
    "\n",
    "# Import MNE-BIDS processing\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "\n",
    "\n",
    "# Import MNE-NIRS processing\n",
    "from mne_nirs.channels import get_long_channels, picks_pair_to_idx\n",
    "from mne_nirs.datasets import fnirs_motor_group\n",
    "from mne_nirs.signal_enhancement import (enhance_negative_correlation, short_channel_regression)\n",
    "from mne_nirs.channels import (get_long_channels,\n",
    "                               get_short_channels,\n",
    "                               picks_pair_to_idx)\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import compress\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from mne_nirs.experimental_design import make_first_level_design_matrix\n",
    "from mne_nirs.statistics import run_glm, statsmodels_to_results\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from mne.annotations import Annotations\n",
    "# Set general parameters\n",
    "set_log_level(\"WARNING\")  # Don't show info, as it is repetitive for many subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f88be5",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3116583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_epochs(max_data, min_data, condition_name, threshold_factor=2, max_reject_ratio=0.25):\n",
    "    thresholds = {\n",
    "        \"Control\": {\"mean_max\": 4.16e-6, \"mean_min\": -4.23e-6, \"std_max\": 2.51e-6, \"std_min\": 2.32e-6},\n",
    "        \"Noise\": {\"mean_max\": 6.08e-6, \"mean_min\": -3.61e-6, \"std_max\": 2.55e-6, \"std_min\": 1.54e-6},\n",
    "        \"Speech\": {\"mean_max\": 7.16e-6, \"mean_min\": -3.88e-6, \"std_max\": 3.16e-6, \"std_min\": 1.5e-6},\n",
    "    }\n",
    "\n",
    "    mean_max = thresholds[condition_name][\"mean_max\"]\n",
    "    mean_min = thresholds[condition_name][\"mean_min\"]\n",
    "    std_max = thresholds[condition_name][\"std_max\"]\n",
    "    std_min = thresholds[condition_name][\"std_min\"]\n",
    "\n",
    "    upper_bound_max = mean_max + (threshold_factor * std_max)\n",
    "    lower_bound_min = mean_min - (threshold_factor * std_min)\n",
    "\n",
    "    rejection_scores = []  # (epoch_idx, num_bad_channels, total_violation)\n",
    "\n",
    "    for epoch_idx in range(max_data.shape[0]):\n",
    "        epoch_max = max_data[epoch_idx, :]\n",
    "        epoch_min = min_data[epoch_idx, :]\n",
    "\n",
    "        bad_max = epoch_max > upper_bound_max\n",
    "        bad_min = epoch_min < lower_bound_min\n",
    "        bad_channels = bad_max | bad_min\n",
    "\n",
    "        num_bad_channels = np.sum(bad_channels)\n",
    "\n",
    "        if num_bad_channels > 0:\n",
    "            max_violation = np.sum(epoch_max[bad_max] - upper_bound_max)\n",
    "            min_violation = np.sum(lower_bound_min - epoch_min[bad_min])\n",
    "            total_violation = max_violation + min_violation\n",
    "\n",
    "            rejection_scores.append((epoch_idx, num_bad_channels, total_violation))\n",
    "\n",
    "    # Sort by: 1) num_bad_channels DESC, 2) total_violation DESC\n",
    "    sorted_scores = sorted(rejection_scores, key=lambda x: (-x[1], -x[2]))\n",
    "\n",
    "    max_allowed_rejections = int(max_reject_ratio * max_data.shape[0])\n",
    "    rejected_epochs = [idx for idx, _, _ in sorted_scores[:max_allowed_rejections]]\n",
    "\n",
    "    # Identify good epochs\n",
    "    all_epochs = set(range(max_data.shape[0]))\n",
    "    good_epochs = sorted(list(all_epochs - set(rejected_epochs)))\n",
    "    bad_epochs = sorted(rejected_epochs)\n",
    "\n",
    "    # Remove rejected epochs\n",
    "    cleaned_max = np.delete(max_data, rejected_epochs, axis=0)\n",
    "    cleaned_min = np.delete(min_data, rejected_epochs, axis=0)\n",
    "\n",
    "    # Create dynamic variable names\n",
    "    condition_upper = condition_name.upper()\n",
    "    good_key = f\"{condition_upper}_GOOD_IDX\"\n",
    "    bad_key = f\"{condition_upper}_BAD_IDX\"\n",
    "\n",
    "    # Return cleaned data and dictionaries of indexes\n",
    "    return cleaned_max, cleaned_min, {\n",
    "        good_key: good_epochs,\n",
    "        bad_key: bad_epochs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3122a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping the signal before sci calculation\n",
    "def preprocessing_glm_ROI(bids_path, subject_id, session_id, id):\n",
    "    print(f\"Processing subject {subject_id} session {session_id}...\")\n",
    "    # Read data with annotations in BIDS format\n",
    "    raw_intensity = read_raw_bids(bids_path=bids_path, verbose=False)\n",
    "    raw_intensity.annotations.set_durations({'Control' : 5, 'Noise' : 5, 'Speech' : 5.25})\n",
    "    # Get the events locations\n",
    "    Breaks, _ = mne.events_from_annotations(raw_intensity, {'Xstart': 4, 'Xend': 5})\n",
    "    AllEvents, _ = mne.events_from_annotations(raw_intensity)\n",
    "    ControlEvents, _ = mne.events_from_annotations(raw_intensity, {'Control': 1})\n",
    "    NoiseEvents, _ = mne.events_from_annotations(raw_intensity, {'Noise': 2})\n",
    "    SpeechEvents, _ = mne.events_from_annotations(raw_intensity, {'Speech': 3})\n",
    "    Breaks = Breaks[:, 0] / raw_intensity.info['sfreq']\n",
    "    LastEvent = AllEvents[-1, 0] / raw_intensity.info['sfreq']\n",
    "    \n",
    "    if len(Breaks) % 2 == 0:\n",
    "        raise ValueError(\"Breaks array should have an odd number of elements.\")\n",
    "    \n",
    "    original_duration = raw_intensity.times[-1] - raw_intensity.times[0]\n",
    "    \n",
    "    # Cropping dataset\n",
    "    cropped_intensity = raw_intensity.copy().crop(Breaks[0], Breaks[1])\n",
    "    for j in range(2, len(Breaks) - 1, 2):\n",
    "        block = raw_intensity.copy().crop(Breaks[j], Breaks[j + 1])\n",
    "        cropped_intensity.append(block)\n",
    "    cropped_intensity.append(raw_intensity.copy().crop(Breaks[-1], LastEvent + 15.25))\n",
    "    \n",
    "    cropped_duration = cropped_intensity.times[-1] - cropped_intensity.times[0]\n",
    "    #print(f\"Cropped duration: {cropped_duration:.2f} seconds\")\n",
    "    \n",
    "    if cropped_duration >= original_duration:\n",
    "        print(f\"WARNING: Cropping did not reduce duration!\")\n",
    "    \n",
    "    raw_intensity_cropped = cropped_intensity.copy()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Remove break annotations\n",
    "    #print(\"Removing break annotations for the orginal raw...\")\n",
    "    raw_intensity.annotations.delete(np.where(\n",
    "        (raw_intensity.annotations.description == 'Xstart') | \n",
    "        (raw_intensity.annotations.description == 'Xend') | \n",
    "        (raw_intensity.annotations.description == 'BAD boundary') | \n",
    "        (raw_intensity.annotations.description == 'EDGE boundary')\n",
    "    )[0])\n",
    "    \n",
    "    raw_intensity_cropped.annotations.delete(np.where(\n",
    "        (raw_intensity_cropped.annotations.description == 'Xstart') | \n",
    "        (raw_intensity_cropped.annotations.description == 'Xend') | \n",
    "        (raw_intensity_cropped.annotations.description == 'BAD boundary') | \n",
    "        (raw_intensity_cropped.annotations.description == 'EDGE boundary')\n",
    "    )[0]) \n",
    "    \n",
    "    # Convert signal to optical density and determine bad channels\n",
    "    raw_od = optical_density(raw_intensity)\n",
    "    raw_od_cropped = optical_density(raw_intensity_cropped)\n",
    "    \n",
    "    # get the total number of short channels\n",
    "    short_chs = get_short_channels(raw_od)\n",
    "    tot_number_of_short_channels = len(short_chs.ch_names)\n",
    "    \n",
    "    # sci calculated\n",
    "    sci = scalp_coupling_index(raw_od_cropped, l_freq=0.7, h_freq=1.45)\n",
    "    bad_channels= list(compress(raw_od.ch_names, sci < 0.8))\n",
    "    \n",
    "    if len(bad_channels) > 55:\n",
    "        print(f\"❌ Too many bad channels ({len(bad_channels)}). Excluding subject from analysis.\")\n",
    "        return None\n",
    "    \n",
    "    raw_od.info[\"bads\"] = bad_channels\n",
    "    raw_intensity_cropped.info[\"bads\"] = bad_channels\n",
    "    \n",
    "    raw_od = temporal_derivative_distribution_repair(raw_od)\n",
    "    raw_od_cropped = temporal_derivative_distribution_repair(raw_od_cropped)\n",
    "\n",
    "    \n",
    "     # Get long channels\n",
    "    long_chs = get_long_channels(raw_od)\n",
    "    bad_long_chs = long_chs.info[\"bads\"]\n",
    "    \n",
    "    # print the number of short bad channels\n",
    "    len_bad_short_chs = len(bad_channels) - len(bad_long_chs)\n",
    "    \n",
    "    # Determine if there are short channels\n",
    "    len_bad_short_chs = len(bad_channels) - len(bad_long_chs)\n",
    "    num_good_short_channels = tot_number_of_short_channels - len_bad_short_chs\n",
    "    \n",
    "    # Determine if there are short channels\n",
    "    if num_good_short_channels < 4:\n",
    "        print(\"❌ No short channels found. Skipping the subject.\")\n",
    "        return None, None, None, None, None # Keep the data unchanged\n",
    "    else:\n",
    "        \n",
    "        raw_od_corrected = short_channel_regression(raw_od)\n",
    "        \n",
    "    # short-channel regression subtracts a scaled version of the signal obtained from the nearest short channel from the signal obtained from the long channel. \n",
    "    # Convert to haemoglobin and filter\n",
    "    raw_haemo_bef = beer_lambert_law(raw_od_corrected, ppf=0.1)\n",
    "    \n",
    "    raw_haemo_bef = get_long_channels(raw_haemo_bef, min_dist=0.02) \n",
    "\n",
    "    #low-pass\n",
    "    raw_haemo_bef = raw_haemo_bef.filter(l_freq = None, h_freq = 0.2,  \n",
    "                                 method=\"iir\", iir_params =dict(order=5, ftype='butter'))\n",
    "    #high-pass\n",
    "    raw_haemo_bef= raw_haemo_bef.filter(l_freq =  0.05, h_freq = None, method=\"iir\", iir_params =dict(order=5, ftype='butter'))\n",
    "    \n",
    "    # Create epochs before filtering\n",
    "    all_events, all_event_dict = mne.events_from_annotations(raw_haemo_bef)\n",
    "    epochs = mne.Epochs(\n",
    "        raw_haemo_bef,\n",
    "        all_events,\n",
    "        event_id=all_event_dict,\n",
    "        tmin=-5,\n",
    "        tmax=15,\n",
    "        reject=dict(hbo=100e-6),\n",
    "        reject_by_annotation=True,\n",
    "        proj=True,\n",
    "        baseline=(None, 0),\n",
    "        detrend=1,\n",
    "        preload=True,\n",
    "        verbose=None,\n",
    "    )\n",
    "    \n",
    "    # EPOCH REJECTION: WE WANT TO CREATE NEW ANNOATIONS MARKING THE GOOD EPOCHS FOR EACH CONDITION\n",
    "    \n",
    "    \n",
    "    # === EPOCH REJECTION ===\n",
    "    bad_ch = epochs.info['bads']\n",
    "    epochs.drop_channels(bad_ch)\n",
    "    epochs_before_cleaning = epochs.copy()\n",
    "\n",
    "    hbo_data = epochs.copy().pick(\"hbo\")\n",
    "    data = hbo_data.get_data()\n",
    "    ev = epochs.events[:, 2]\n",
    "    index_column = np.arange(0, len(ev)).reshape(-1, 1)\n",
    "    updated_matrix = np.hstack((index_column, ev.reshape(-1, 1)))\n",
    "\n",
    "    time_slice = data[:, :, 26:105]\n",
    "    max_values = np.max(time_slice, axis=2)\n",
    "    min_values = np.min(time_slice, axis=2)\n",
    "\n",
    "    control_idx = updated_matrix[updated_matrix[:, 1] == 1][:, 0]\n",
    "    noise_idx = updated_matrix[updated_matrix[:, 1] == 2][:, 0]\n",
    "    speech_idx = updated_matrix[updated_matrix[:, 1] == 3][:, 0]\n",
    "\n",
    "    control_max = max_values[control_idx, :]\n",
    "    noise_max = max_values[noise_idx, :]\n",
    "    speech_max = max_values[speech_idx, :]\n",
    "\n",
    "    control_min = min_values[control_idx, :]\n",
    "    noise_min = min_values[noise_idx, :]\n",
    "    speech_min = min_values[speech_idx, :]\n",
    "\n",
    "    cleaned_max, cleaned_min, idx_dict = reject_epochs(control_max, control_min, \"Control\")\n",
    "    CONTROL_GOOD_IDX = idx_dict[\"CONTROL_GOOD_IDX\"]\n",
    "    CONTROL_BAD_IDX = idx_dict[\"CONTROL_BAD_IDX\"]\n",
    "    \n",
    "    cleaned_max, cleaned_min, idx_dict = reject_epochs(noise_max, noise_min, \"Noise\")\n",
    "    NOISE_GOOD_IDX = idx_dict[\"NOISE_GOOD_IDX\"]\n",
    "    NOISE_BAD_IDX = idx_dict[\"NOISE_BAD_IDX\"]\n",
    "    \n",
    "    cleaned_max, cleaned_min, idx_dict = reject_epochs(speech_max, speech_min, \"Speech\")\n",
    "    SPEECH_GOOD_IDX = idx_dict[\"SPEECH_GOOD_IDX\"]\n",
    "    SPEECH_BAD_IDX = idx_dict[\"SPEECH_BAD_IDX\"]\n",
    "\n",
    "    \n",
    "    raw_haemo= raw_haemo_bef.copy()\n",
    "    \n",
    "    # --- CONTROL ---\n",
    "    ControlEvents_good = ControlEvents[CONTROL_GOOD_IDX]\n",
    "    onsets_control = raw_haemo.times[ControlEvents_good[:, 0]]\n",
    "    durations_control = [0] * len(onsets_control)\n",
    "    descriptions_control = ['Control'] * len(onsets_control)\n",
    "    good_annotations_control = Annotations(onset=onsets_control, duration=durations_control, description=descriptions_control)\n",
    "\n",
    "    # --- NOISE ---\n",
    "    NoiseEvents_good = NoiseEvents[NOISE_GOOD_IDX]\n",
    "    onsets_noise = raw_haemo.times[NoiseEvents_good[:, 0]]\n",
    "    durations_noise = [0] * len(onsets_noise)\n",
    "    descriptions_noise = ['Noise'] * len(onsets_noise)\n",
    "    good_annotations_noise = Annotations(onset=onsets_noise, duration=durations_noise, description=descriptions_noise)\n",
    "\n",
    "    # --- SPEECH ---\n",
    "    SpeechEvents_good = SpeechEvents[SPEECH_GOOD_IDX]\n",
    "    onsets_speech = raw_haemo.times[SpeechEvents_good[:, 0]]\n",
    "    durations_speech = [0] * len(onsets_speech)\n",
    "    descriptions_speech = ['Speech'] * len(onsets_speech)\n",
    "    good_annotations_speech = Annotations(onset=onsets_speech, duration=durations_speech, description=descriptions_speech)\n",
    "\n",
    "    # --- COMBINE AND SET ---\n",
    "    combined_annotations = good_annotations_control + good_annotations_noise + good_annotations_speech\n",
    "    raw_haemo.set_annotations(combined_annotations)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Continue with GLM analysis\n",
    "    events, event_dict = mne.events_from_annotations(raw_haemo)\n",
    "    isis, names = mne_nirs.experimental_design.longest_inter_annotation_interval(raw_haemo)\n",
    "    design_matrix = make_first_level_design_matrix(\n",
    "        raw_haemo,\n",
    "        drift_model='cosine',\n",
    "        high_pass=1/(2*max(isis)),\n",
    "        hrf_model='spm',\n",
    "        stim_dur=5.125\n",
    "    )\n",
    "    glm_est = run_glm(raw_haemo, design_matrix)\n",
    "\n",
    "\n",
    "    # Define ROI channel pairs\n",
    "    left = [[4, 2], [4, 3], [5, 2], [5, 3], [5, 4], [5, 5]]\n",
    "    right = [[10, 9], [10, 10], [10, 11], [10, 12], [11, 11], [11, 12]]\n",
    "    back = [[6, 6], [6, 8], [7, 6], [7, 7], [7, 8], [8, 7], [8, 8], [9, 8]] \n",
    "    front = [[1, 1], [2, 1], [3, 1], [3, 2], [12, 1]]\n",
    "    noise= [[10, 11], [5, 3], [11, 11], [10, 9], [10, 12], [10, 10]]\n",
    "    speech= [[10, 11], [10, 10], [10, 12], [11, 12], [1, 1], [10, 9], [8, 7], [7, 7], [8, 8]]\n",
    "    common= [[10, 11], [10, 9], [10, 12], [10, 10]]\n",
    "    only_noise= [[5, 3], [11, 11]]\n",
    "    only_speech= [ [11, 12], [1, 1], [10, 9], [8, 7], [7, 7], [8, 8]]\n",
    "    New_Speech= [[2, 1], [5, 5], [6, 8], [7,7], [8,8], [9,8], [10,9], [12, 1]]\n",
    "    New_Noise= [[2, 1], [3, 1], [6, 8], [7, 6], [9, 8]]\n",
    "    \n",
    "\n",
    "    # Generate index picks for each ROI\n",
    "    roi_picks = dict(\n",
    "        Left= picks_pair_to_idx(raw_haemo, left, on_missing=\"ignore\"),\n",
    "        Right= picks_pair_to_idx(raw_haemo, right, on_missing=\"ignore\"),\n",
    "        Back= picks_pair_to_idx(raw_haemo, back, on_missing=\"ignore\"),\n",
    "        Front= picks_pair_to_idx(raw_haemo, front, on_missing=\"ignore\"),\n",
    "        Noise= picks_pair_to_idx(raw_haemo, noise, on_missing=\"ignore\"),\n",
    "        Speech= picks_pair_to_idx(raw_haemo, speech, on_missing=\"ignore\"),\n",
    "        Common= picks_pair_to_idx(raw_haemo, common, on_missing=\"ignore\"),\n",
    "        OnlyNoise= picks_pair_to_idx(raw_haemo, only_noise, on_missing=\"ignore\"),\n",
    "        OnlySpeech= picks_pair_to_idx(raw_haemo, only_speech, on_missing=\"ignore\"),\n",
    "        New_Speech= picks_pair_to_idx(raw_haemo, New_Speech, on_missing=\"ignore\"),\n",
    "        New_Noise= picks_pair_to_idx(raw_haemo, New_Noise, on_missing=\"ignore\"),\n",
    "    )\n",
    "    \n",
    "    cha= glm_est.to_dataframe()\n",
    "    \n",
    "    roi= glm_est.to_dataframe_region_of_interest(\n",
    "        roi_picks, design_matrix.columns, demographic_info=True\n",
    "    )\n",
    "    \n",
    "    # Define left vs right tapping contrast\n",
    "    contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "    basic_conts = dict(\n",
    "        [(column, contrast_matrix[i]) for i, column in enumerate(design_matrix.columns)]\n",
    "    )\n",
    "    contrast_LvR = basic_conts[\"Noise\"] - basic_conts[\"Speech\"]\n",
    "\n",
    "    # Compute defined contrast\n",
    "    contrast = glm_est.compute_contrast(contrast_LvR)\n",
    "    con = contrast.to_dataframe()\n",
    "\n",
    "    # Add the participant sub to the dataframes\n",
    "    roi[\"ID\"] = cha[\"ID\"] = con[\"ID\"] = id\n",
    "    \n",
    "    roi[\"Subject\"] = cha[\"Subject\"] = con[\"Subject\"] = subject_id\n",
    "    \n",
    "    # Add the session to the dataframes\n",
    "    roi[\"session\"] = cha[\"session\"] = con[\"session\"] = session_id\n",
    "\n",
    "    # Convert to uM for nicer plotting below.\n",
    "    cha[\"theta\"] = [t * 1.0e6 for t in cha[\"theta\"]]\n",
    "    roi[\"theta\"] = [t * 1.0e6 for t in roi[\"theta\"]]\n",
    "    con[\"effect\"] = [t * 1.0e6 for t in con[\"effect\"]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return raw_haemo, roi, cha, con\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b326360",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad12785c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected subjects: ['01', '02', '03', '04', '05', '07', '08', '10', '11', '12', '13', '16', '17', '19', '21', '24']\n",
      "Processing subject 01 session 1...\n",
      "Processing subject 01 session 2...\n",
      "Processing subject 02 session 1...\n",
      "Processing subject 02 session 2...\n",
      "Processing subject 03 session 1...\n",
      "Processing subject 03 session 2...\n",
      "Processing subject 04 session 1...\n",
      "Processing subject 04 session 2...\n",
      "Processing subject 05 session 1...\n",
      "Processing subject 05 session 2...\n",
      "Processing subject 07 session 1...\n",
      "Processing subject 07 session 2...\n",
      "Processing subject 08 session 1...\n",
      "Processing subject 08 session 2...\n",
      "Processing subject 10 session 1...\n",
      "Processing subject 10 session 2...\n",
      "Processing subject 11 session 1...\n",
      "Processing subject 11 session 2...\n",
      "Processing subject 12 session 1...\n",
      "Processing subject 12 session 2...\n",
      "Processing subject 13 session 1...\n",
      "Processing subject 13 session 2...\n",
      "Processing subject 16 session 1...\n",
      "Processing subject 16 session 2...\n",
      "Processing subject 17 session 1...\n",
      "Processing subject 17 session 2...\n",
      "Processing subject 19 session 1...\n",
      "Processing subject 19 session 2...\n",
      "Processing subject 21 session 1...\n",
      "Processing subject 21 session 2...\n",
      "Processing subject 24 session 1...\n",
      "Processing subject 24 session 2...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bids_root = r\"C:\\Datasets\\Test-retest study\\bids_dataset\"\n",
    "subject_list = sorted([d for d in os.listdir(bids_root) if d.startswith(\"sub-\")])\n",
    "subject_list = [s.replace(\"sub-\", \"\") for s in subject_list]\n",
    "#subject_list = subject_list[:1]  # Limit to first 3 subjects for testing\n",
    "\n",
    "print(\"Detected subjects:\", subject_list)\n",
    "subjects_df = pd.DataFrame(columns=[\"subject\", \"session\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#optode_subject_sessions = {optode: pd.DataFrame(columns=[\"subject\", \"session\"]) for optode in optodes}\n",
    "\n",
    "df_roi = pd.DataFrame()  # To store region of interest results\n",
    "df_cha = pd.DataFrame()  # To store channel level results\n",
    "df_con = pd.DataFrame()  # To store channel level contrast results\n",
    "id = 0\n",
    "# Loop through subjects and sessions\n",
    "for sub in subject_list:\n",
    "    for ses in range(1, 3):\n",
    "        \n",
    "        bids_path = BIDSPath(\n",
    "                subject=f\"{sub}\",\n",
    "                session=f\"{ses:02d}\",\n",
    "                task=\"auditory\",\n",
    "                datatype=\"nirs\",\n",
    "                root=bids_root,\n",
    "                suffix=\"nirs\",\n",
    "                extension=\".snirf\",\n",
    "            )\n",
    "            \n",
    "        raw_haemo, roi, cha, con = preprocessing_glm_ROI(bids_path, sub, ses, id)\n",
    "        if raw_haemo is None:\n",
    "            print(f\"⚠️ No data for Subject {sub}, Session {ses:02d}. Skipping...\")\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            # Append individual results to all participants\n",
    "            df_roi = pd.concat([df_roi, roi], ignore_index=True)\n",
    "            df_cha = pd.concat([df_cha, cha], ignore_index=True)\n",
    "            df_con = pd.concat([df_con, con], ignore_index=True)\n",
    "            id= id + 1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1854b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for channel S1_D1 hbo...\n",
      "Fitting model for channel S2_D1 hbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for channel S3_D1 hbo...\n",
      "Fitting model for channel S3_D2 hbo...\n",
      "Fitting model for channel S4_D2 hbo...\n",
      "Fitting model for channel S4_D3 hbo...\n",
      "Fitting model for channel S5_D2 hbo...\n",
      "Fitting model for channel S5_D3 hbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for channel S5_D4 hbo...\n",
      "Fitting model for channel S5_D5 hbo...\n",
      "Fitting model for channel S6_D6 hbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for channel S6_D8 hbo...\n",
      "Fitting model for channel S7_D6 hbo...\n",
      "Fitting model for channel S7_D7 hbo...\n",
      "Fitting model for channel S7_D8 hbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for channel S8_D7 hbo...\n",
      "Fitting model for channel S8_D8 hbo...\n",
      "Fitting model for channel S9_D8 hbo...\n",
      "Fitting model for channel S10_D9 hbo...\n",
      "Fitting model for channel S10_D10 hbo...\n",
      "Fitting model for channel S10_D11 hbo...\n",
      "Fitting model for channel S10_D12 hbo...\n",
      "Fitting model for channel S11_D11 hbo...\n",
      "Fitting model for channel S11_D12 hbo...\n",
      "Fitting model for channel S12_D1 hbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\anaconda3\\envs\\mne\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comparison",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Beta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "StdErr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4066580f-7dc5-48fe-8745-4ad9f2530572",
       "rows": [
        [
         "2",
         "S2_D1 hbo",
         "Condition[T.Noise]",
         "-1.9214880818083215",
         "0.7688914868312304",
         "-2.4990367492911036",
         "0.01245313963389885"
        ],
        [
         "3",
         "S2_D1 hbo",
         "Condition[T.Speech]",
         "-2.3858787391328926",
         "0.7688914868312304",
         "-3.103010996994673",
         "0.001915625219919078"
        ],
        [
         "4",
         "S3_D1 hbo",
         "Condition[T.Noise]",
         "-2.1909811708888034",
         "0.8126074061124383",
         "-2.6962357891501214",
         "0.007012800639625423"
        ],
        [
         "5",
         "S3_D1 hbo",
         "Condition[T.Speech]",
         "-2.124316555068424",
         "0.8126074061124383",
         "-2.614197875984517",
         "0.008943722163229008"
        ],
        [
         "7",
         "S3_D2 hbo",
         "Condition[T.Speech]",
         "-3.426155749564843",
         "1.0972596882390917",
         "-3.122465708243797",
         "0.0017934299683547816"
        ],
        [
         "13",
         "S5_D2 hbo",
         "Condition[T.Speech]",
         "-3.398747022329553",
         "1.1995938346029005",
         "-2.8332481580773",
         "0.004607759974310905"
        ],
        [
         "19",
         "S5_D5 hbo",
         "Condition[T.Speech]",
         "-2.6088410296358053",
         "1.2857086272253244",
         "-2.0291075088030794",
         "0.04244734127338472"
        ],
        [
         "22",
         "S6_D8 hbo",
         "Condition[T.Noise]",
         "-2.0084761300754113",
         "0.771238307002291",
         "-2.604222471627625",
         "0.009208296336582166"
        ],
        [
         "23",
         "S6_D8 hbo",
         "Condition[T.Speech]",
         "-3.0391261698728447",
         "0.771238307002291",
         "-3.9405798989492062",
         "8.12848705946769e-05"
        ],
        [
         "24",
         "S7_D6 hbo",
         "Condition[T.Noise]",
         "-2.3181888424364847",
         "1.1653729155793826",
         "-1.989224918003146",
         "0.04667638270364752"
        ],
        [
         "25",
         "S7_D6 hbo",
         "Condition[T.Speech]",
         "-3.8302531855275532",
         "1.1653729155793828",
         "-3.286718898579589",
         "0.0010136196020766213"
        ],
        [
         "27",
         "S7_D7 hbo",
         "Condition[T.Speech]",
         "-2.651176847170652",
         "0.8048638575690666",
         "-3.293944463077285",
         "0.000987920157518799"
        ],
        [
         "29",
         "S7_D8 hbo",
         "Condition[T.Speech]",
         "-4.435217611912504",
         "1.6176785540003615",
         "-2.741717506821515",
         "0.006111888048872637"
        ],
        [
         "31",
         "S8_D7 hbo",
         "Condition[T.Speech]",
         "-2.667962823662824",
         "1.2351592661028195",
         "-2.1600152278991462",
         "0.03077149073903487"
        ],
        [
         "33",
         "S8_D8 hbo",
         "Condition[T.Speech]",
         "-3.441678495120047",
         "1.3600880352711078",
         "-2.530482149586746",
         "0.011390588069444747"
        ],
        [
         "34",
         "S9_D8 hbo",
         "Condition[T.Noise]",
         "-2.376118561197841",
         "0.914602071043665",
         "-2.5979807354759425",
         "0.009377375475501567"
        ],
        [
         "35",
         "S9_D8 hbo",
         "Condition[T.Speech]",
         "-3.246637126837639",
         "0.9146020710436649",
         "-3.549781079254344",
         "0.00038555162884468285"
        ],
        [
         "37",
         "S10_D9 hbo",
         "Condition[T.Speech]",
         "-2.527856173871848",
         "0.9862644631658737",
         "-2.563061195328401",
         "0.010375375947466767"
        ],
        [
         "49",
         "S12_D1 hbo",
         "Condition[T.Speech]",
         "-1.642507430681304",
         "0.7980990019274158",
         "-2.058024664502317",
         "0.039587765825153186"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Beta</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>z</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2_D1 hbo</td>\n",
       "      <td>Condition[T.Noise]</td>\n",
       "      <td>-1.921488</td>\n",
       "      <td>0.768891</td>\n",
       "      <td>-2.499037</td>\n",
       "      <td>0.012453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2_D1 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-2.385879</td>\n",
       "      <td>0.768891</td>\n",
       "      <td>-3.103011</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S3_D1 hbo</td>\n",
       "      <td>Condition[T.Noise]</td>\n",
       "      <td>-2.190981</td>\n",
       "      <td>0.812607</td>\n",
       "      <td>-2.696236</td>\n",
       "      <td>0.007013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S3_D1 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-2.124317</td>\n",
       "      <td>0.812607</td>\n",
       "      <td>-2.614198</td>\n",
       "      <td>0.008944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S3_D2 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-3.426156</td>\n",
       "      <td>1.097260</td>\n",
       "      <td>-3.122466</td>\n",
       "      <td>0.001793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S5_D2 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-3.398747</td>\n",
       "      <td>1.199594</td>\n",
       "      <td>-2.833248</td>\n",
       "      <td>0.004608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S5_D5 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-2.608841</td>\n",
       "      <td>1.285709</td>\n",
       "      <td>-2.029108</td>\n",
       "      <td>0.042447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S6_D8 hbo</td>\n",
       "      <td>Condition[T.Noise]</td>\n",
       "      <td>-2.008476</td>\n",
       "      <td>0.771238</td>\n",
       "      <td>-2.604222</td>\n",
       "      <td>0.009208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S6_D8 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-3.039126</td>\n",
       "      <td>0.771238</td>\n",
       "      <td>-3.940580</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S7_D6 hbo</td>\n",
       "      <td>Condition[T.Noise]</td>\n",
       "      <td>-2.318189</td>\n",
       "      <td>1.165373</td>\n",
       "      <td>-1.989225</td>\n",
       "      <td>0.046676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S7_D6 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-3.830253</td>\n",
       "      <td>1.165373</td>\n",
       "      <td>-3.286719</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>S7_D7 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-2.651177</td>\n",
       "      <td>0.804864</td>\n",
       "      <td>-3.293944</td>\n",
       "      <td>0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S7_D8 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-4.435218</td>\n",
       "      <td>1.617679</td>\n",
       "      <td>-2.741718</td>\n",
       "      <td>0.006112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>S8_D7 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-2.667963</td>\n",
       "      <td>1.235159</td>\n",
       "      <td>-2.160015</td>\n",
       "      <td>0.030771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S8_D8 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-3.441678</td>\n",
       "      <td>1.360088</td>\n",
       "      <td>-2.530482</td>\n",
       "      <td>0.011391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S9_D8 hbo</td>\n",
       "      <td>Condition[T.Noise]</td>\n",
       "      <td>-2.376119</td>\n",
       "      <td>0.914602</td>\n",
       "      <td>-2.597981</td>\n",
       "      <td>0.009377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>S9_D8 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-3.246637</td>\n",
       "      <td>0.914602</td>\n",
       "      <td>-3.549781</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>S10_D9 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-2.527856</td>\n",
       "      <td>0.986264</td>\n",
       "      <td>-2.563061</td>\n",
       "      <td>0.010375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>S12_D1 hbo</td>\n",
       "      <td>Condition[T.Speech]</td>\n",
       "      <td>-1.642507</td>\n",
       "      <td>0.798099</td>\n",
       "      <td>-2.058025</td>\n",
       "      <td>0.039588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Channel           Comparison      Beta    StdErr         z         p\n",
       "2    S2_D1 hbo   Condition[T.Noise] -1.921488  0.768891 -2.499037  0.012453\n",
       "3    S2_D1 hbo  Condition[T.Speech] -2.385879  0.768891 -3.103011  0.001916\n",
       "4    S3_D1 hbo   Condition[T.Noise] -2.190981  0.812607 -2.696236  0.007013\n",
       "5    S3_D1 hbo  Condition[T.Speech] -2.124317  0.812607 -2.614198  0.008944\n",
       "7    S3_D2 hbo  Condition[T.Speech] -3.426156  1.097260 -3.122466  0.001793\n",
       "13   S5_D2 hbo  Condition[T.Speech] -3.398747  1.199594 -2.833248  0.004608\n",
       "19   S5_D5 hbo  Condition[T.Speech] -2.608841  1.285709 -2.029108  0.042447\n",
       "22   S6_D8 hbo   Condition[T.Noise] -2.008476  0.771238 -2.604222  0.009208\n",
       "23   S6_D8 hbo  Condition[T.Speech] -3.039126  0.771238 -3.940580  0.000081\n",
       "24   S7_D6 hbo   Condition[T.Noise] -2.318189  1.165373 -1.989225  0.046676\n",
       "25   S7_D6 hbo  Condition[T.Speech] -3.830253  1.165373 -3.286719  0.001014\n",
       "27   S7_D7 hbo  Condition[T.Speech] -2.651177  0.804864 -3.293944  0.000988\n",
       "29   S7_D8 hbo  Condition[T.Speech] -4.435218  1.617679 -2.741718  0.006112\n",
       "31   S8_D7 hbo  Condition[T.Speech] -2.667963  1.235159 -2.160015  0.030771\n",
       "33   S8_D8 hbo  Condition[T.Speech] -3.441678  1.360088 -2.530482  0.011391\n",
       "34   S9_D8 hbo   Condition[T.Noise] -2.376119  0.914602 -2.597981  0.009377\n",
       "35   S9_D8 hbo  Condition[T.Speech] -3.246637  0.914602 -3.549781  0.000386\n",
       "37  S10_D9 hbo  Condition[T.Speech] -2.527856  0.986264 -2.563061  0.010375\n",
       "49  S12_D1 hbo  Condition[T.Speech] -1.642507  0.798099 -2.058025  0.039588"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Step 1: Filter for session 1 and hbo only\n",
    "ch_summary = df_cha.query(\"Condition in ['Control', 'Noise', 'Speech'] and Chroma == 'hbo' and session == 1\").copy()\n",
    "#ch_summary = df_cha.query(\"Condition in ['Control', 'Noise', 'Speech'] and Chroma == 'hbo'\").copy()\n",
    "\n",
    "# Step 2: Ensure 'Condition' is categorical with 'Control' as the reference\n",
    "ch_summary[\"Condition\"] = pd.Categorical(\n",
    "    ch_summary[\"Condition\"], categories=[\"Control\", \"Noise\", \"Speech\"], ordered=True\n",
    ")\n",
    "\n",
    "# Step 3: Fit per-channel models and collect results\n",
    "results = []\n",
    "\n",
    "for ch in ch_summary[\"ch_name\"].unique():\n",
    "    print(f\"Fitting model for channel {ch}...\")\n",
    "    ch_data = ch_summary[ch_summary[\"ch_name\"] == ch].copy()\n",
    "\n",
    "    try:\n",
    "        model = smf.mixedlm(\n",
    "            \"theta ~ Condition\",  # Compare Noise & Speech vs Control\n",
    "            ch_data,\n",
    "            groups=ch_data[\"Subject\"],\n",
    "        ).fit(method=\"powell\")\n",
    "\n",
    "        # Extract parameters and p-values directly\n",
    "        for param_name in model.params.index:\n",
    "            if \"Condition[T.Noise]\" in param_name or \"Condition[T.Speech]\" in param_name:\n",
    "                results.append({\n",
    "                    \"Channel\": ch,\n",
    "                    \"Comparison\": param_name,\n",
    "                    \"Beta\": model.params[param_name],\n",
    "                    \"StdErr\": model.bse[param_name],\n",
    "                    \"z\": model.tvalues[param_name],\n",
    "                    \"p\": model.pvalues[param_name]\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Model failed for channel {ch}: {e}\")\n",
    "\n",
    "# Step 4: Create DataFrame from results\n",
    "significant = pd.DataFrame(results)\n",
    "\n",
    "# Step 5: Filter for significance\n",
    "significant = significant[significant[\"p\"] < 0.05]\n",
    "\n",
    "# View significant results\n",
    "significant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "953bd0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mixed model for Left...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    4.8431   \n",
      "Min. group size:          6             Log-Likelihood:           -211.5980\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                        -0.163    0.588 -0.277 0.782 -1.315  0.989\n",
      "Condition[T.Noise]               -0.865    0.778 -1.112 0.266 -2.390  0.660\n",
      "Condition[T.Speech]              -0.329    0.778 -0.423 0.672 -1.854  1.196\n",
      "session[T.2]                      0.861    0.778  1.107 0.268 -0.664  2.386\n",
      "Condition[T.Noise]:session[T.2]  -0.134    1.100 -0.122 0.903 -2.290  2.023\n",
      "Condition[T.Speech]:session[T.2] -1.124    1.100 -1.022 0.307 -3.281  1.032\n",
      "Group Var                         0.681    0.270                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for Right...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    3.1245   \n",
      "Min. group size:          6             Log-Likelihood:           -197.4347\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                         0.118    0.537  0.219 0.827 -0.935  1.171\n",
      "Condition[T.Noise]                0.351    0.625  0.562 0.574 -0.873  1.576\n",
      "Condition[T.Speech]              -0.314    0.625 -0.502 0.616 -1.539  0.911\n",
      "session[T.2]                      0.305    0.625  0.488 0.626 -0.920  1.530\n",
      "Condition[T.Noise]:session[T.2]  -0.420    0.884 -0.475 0.635 -2.152  1.312\n",
      "Condition[T.Speech]:session[T.2] -0.044    0.884 -0.050 0.960 -1.776  1.688\n",
      "Group Var                         1.493    0.456                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for Back...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    3.3830   \n",
      "Min. group size:          6             Log-Likelihood:           -200.4288\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                        -0.131    0.550 -0.238 0.812 -1.209  0.947\n",
      "Condition[T.Noise]               -0.900    0.650 -1.384 0.166 -2.174  0.375\n",
      "Condition[T.Speech]              -2.477    0.650 -3.809 0.000 -3.751 -1.202\n",
      "session[T.2]                      0.422    0.650  0.648 0.517 -0.853  1.696\n",
      "Condition[T.Noise]:session[T.2]  -0.332    0.920 -0.361 0.718 -2.135  1.470\n",
      "Condition[T.Speech]:session[T.2] -0.177    0.920 -0.193 0.847 -1.980  1.625\n",
      "Group Var                         1.454    0.439                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for Front...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    2.8650   \n",
      "Min. group size:          6             Log-Likelihood:           -184.8731\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                        -0.212    0.431 -0.491 0.623 -1.056  0.633\n",
      "Condition[T.Noise]               -0.404    0.598 -0.675 0.500 -1.577  0.769\n",
      "Condition[T.Speech]              -0.800    0.598 -1.336 0.182 -1.972  0.373\n",
      "session[T.2]                      0.913    0.598  1.526 0.127 -0.260  2.086\n",
      "Condition[T.Noise]:session[T.2]  -0.749    0.846 -0.884 0.376 -2.407  0.910\n",
      "Condition[T.Speech]:session[T.2] -0.956    0.846 -1.129 0.259 -2.614  0.703\n",
      "Group Var                         0.105    0.138                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for Noise...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    3.4281   \n",
      "Min. group size:          6             Log-Likelihood:           -200.7974\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                         0.186    0.550  0.337 0.736 -0.892  1.264\n",
      "Condition[T.Noise]                0.240    0.655  0.367 0.714 -1.043  1.523\n",
      "Condition[T.Speech]              -0.367    0.655 -0.561 0.575 -1.650  0.916\n",
      "session[T.2]                      0.083    0.655  0.127 0.899 -1.200  1.366\n",
      "Condition[T.Noise]:session[T.2]  -0.330    0.926 -0.357 0.721 -2.145  1.484\n",
      "Condition[T.Speech]:session[T.2] -0.120    0.926 -0.130 0.897 -1.935  1.694\n",
      "Group Var                         1.412    0.429                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for Speech...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    2.9304   \n",
      "Min. group size:          6             Log-Likelihood:           -193.9058\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                        -0.057    0.511 -0.111 0.912 -1.058  0.945\n",
      "Condition[T.Noise]                0.050    0.605  0.083 0.934 -1.136  1.237\n",
      "Condition[T.Speech]              -0.965    0.605 -1.594 0.111 -2.151  0.221\n",
      "session[T.2]                      0.367    0.605  0.606 0.544 -0.819  1.553\n",
      "Condition[T.Noise]:session[T.2]  -0.307    0.856 -0.358 0.720 -1.984  1.371\n",
      "Condition[T.Speech]:session[T.2] -0.143    0.856 -0.167 0.868 -1.820  1.535\n",
      "Group Var                         1.246    0.405                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for Common...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    4.6909   \n",
      "Min. group size:          6             Log-Likelihood:           -212.1767\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                         0.350    0.602  0.582 0.560 -0.829  1.530\n",
      "Condition[T.Noise]                0.451    0.766  0.589 0.556 -1.050  1.952\n",
      "Condition[T.Speech]              -1.123    0.766 -1.466 0.143 -2.624  0.378\n",
      "session[T.2]                     -0.203    0.766 -0.265 0.791 -1.704  1.298\n",
      "Condition[T.Noise]:session[T.2]  -0.255    1.083 -0.235 0.814 -2.377  1.868\n",
      "Condition[T.Speech]:session[T.2]  0.206    1.083  0.191 0.849 -1.916  2.329\n",
      "Group Var                         1.104    0.348                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for OnlyNoise...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    4.4717   \n",
      "Min. group size:          6             Log-Likelihood:           -213.3536\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                        -0.014    0.639 -0.023 0.982 -1.266  1.238\n",
      "Condition[T.Noise]               -0.033    0.748 -0.045 0.964 -1.499  1.432\n",
      "Condition[T.Speech]               1.014    0.748  1.356 0.175 -0.452  2.479\n",
      "session[T.2]                      0.496    0.748  0.663 0.507 -0.970  1.961\n",
      "Condition[T.Noise]:session[T.2]  -0.275    1.057 -0.260 0.795 -2.347  1.798\n",
      "Condition[T.Speech]:session[T.2] -0.615    1.057 -0.582 0.561 -2.687  1.457\n",
      "Group Var                         2.057    0.530                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for OnlySpeech...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    2.9543   \n",
      "Min. group size:          6             Log-Likelihood:           -194.9235\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                        -0.186    0.523 -0.356 0.722 -1.210  0.838\n",
      "Condition[T.Noise]               -0.205    0.608 -0.337 0.736 -1.396  0.986\n",
      "Condition[T.Speech]              -1.100    0.608 -1.811 0.070 -2.292  0.091\n",
      "session[T.2]                      0.591    0.608  0.973 0.331 -0.600  1.782\n",
      "Condition[T.Noise]:session[T.2]  -0.362    0.859 -0.421 0.674 -2.046  1.322\n",
      "Condition[T.Speech]:session[T.2] -0.378    0.859 -0.439 0.660 -2.062  1.307\n",
      "Group Var                         1.414    0.444                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for New_Speech...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    2.1046   \n",
      "Min. group size:          6             Log-Likelihood:           -175.5667\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                         0.063    0.398  0.158 0.875 -0.718  0.844\n",
      "Condition[T.Noise]               -0.716    0.513 -1.395 0.163 -1.721  0.290\n",
      "Condition[T.Speech]              -1.718    0.513 -3.349 0.001 -2.723 -0.712\n",
      "session[T.2]                      0.299    0.513  0.582 0.560 -0.707  1.304\n",
      "Condition[T.Noise]:session[T.2]  -0.361    0.725 -0.497 0.619 -1.782  1.061\n",
      "Condition[T.Speech]:session[T.2] -0.393    0.725 -0.541 0.588 -1.814  1.029\n",
      "Group Var                         0.436    0.217                           \n",
      "===========================================================================\n",
      "\n",
      "Running mixed model for New_Noise...\n",
      "                   Mixed Linear Model Regression Results\n",
      "===========================================================================\n",
      "Model:                    MixedLM       Dependent Variable:       theta    \n",
      "No. Observations:         96            Method:                   REML     \n",
      "No. Groups:               16            Scale:                    1.8964   \n",
      "Min. group size:          6             Log-Likelihood:           -173.9040\n",
      "Max. group size:          6             Converged:                Yes      \n",
      "Mean group size:          6.0                                              \n",
      "---------------------------------------------------------------------------\n",
      "                                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------------------------\n",
      "Intercept                        -0.248    0.406 -0.610 0.542 -1.044  0.549\n",
      "Condition[T.Noise]               -0.796    0.487 -1.634 0.102 -1.750  0.159\n",
      "Condition[T.Speech]              -1.651    0.487 -3.392 0.001 -2.606 -0.697\n",
      "session[T.2]                      0.868    0.487  1.783 0.075 -0.086  1.822\n",
      "Condition[T.Noise]:session[T.2]  -0.957    0.689 -1.390 0.164 -2.307  0.392\n",
      "Condition[T.Speech]:session[T.2] -0.609    0.689 -0.885 0.376 -1.959  0.740\n",
      "Group Var                         0.745    0.308                           \n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grp_results = df_roi.query(\"Condition in ['Control','Noise', 'Speech']\")\n",
    "\n",
    "for roi in [\"Left\", \"Right\", \"Back\", \"Front\", \"Noise\", \"Speech\", \"Common\", \"OnlyNoise\", \"OnlySpeech\", \"New_Speech\", \"New_Noise\"]:\n",
    "    print(f\"Running mixed model for {roi}...\")\n",
    "    subset = grp_results[(grp_results[\"Chroma\"] == \"hbo\") & (grp_results[\"ROI\"] == roi)].copy()\n",
    "\n",
    "    # Ensure categorical variables\n",
    "    subset[\"Condition\"] = subset[\"Condition\"].astype(\"category\")\n",
    "    subset[\"session\"] = subset[\"session\"].astype(\"category\")\n",
    "    \n",
    "    subset[\"Condition\"] = subset[\"Condition\"].cat.reorder_categories([\"Control\", \"Noise\", \"Speech\"], ordered=True)\n",
    "\n",
    "\n",
    "    # Fit mixed model: Condition + Session as fixed, ID as random intercept\n",
    "    model = smf.mixedlm(\"theta ~ Condition + session + Condition*session\", subset, groups=subset[\"Subject\"])\n",
    "    result = model.fit( method=\"powell\")\n",
    "    print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d4bc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Paired t-test (Control vs Speech) – ROI: Left\n",
      "   t = 1.6444, p = 0.1102\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: Left\n",
      "   t = 1.7396, p = 0.0919\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: Right\n",
      "   t = 0.7064, p = 0.4852\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: Right\n",
      "   t = -0.3566, p = 0.7238\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: Back\n",
      "   t = 5.3728, p = 0.0000\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: Back\n",
      "   t = 2.3721, p = 0.0241\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: Front\n",
      "   t = 2.5301, p = 0.0167\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: Front\n",
      "   t = 1.9955, p = 0.0548\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: Noise\n",
      "   t = 0.9244, p = 0.3624\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: Noise\n",
      "   t = -0.1757, p = 0.8617\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: Speech\n",
      "   t = 2.3354, p = 0.0262\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: Speech\n",
      "   t = 0.2382, p = 0.8133\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: Common\n",
      "   t = 1.8135, p = 0.0794\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: Common\n",
      "   t = -0.6565, p = 0.5163\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: OnlyNoise\n",
      "   t = -1.4165, p = 0.1666\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: OnlyNoise\n",
      "   t = 0.3784, p = 0.7077\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: OnlySpeech\n",
      "   t = 2.7729, p = 0.0093\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: OnlySpeech\n",
      "   t = 0.8566, p = 0.3982\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: New_Speech\n",
      "   t = 4.6631, p = 0.0001\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: New_Speech\n",
      "   t = 2.5922, p = 0.0144\n",
      "------------------------------------------------------------\n",
      "🔹 Paired t-test (Control vs Speech) – ROI: New_Noise\n",
      "   t = 5.0400, p = 0.0000\n",
      "🔹 Paired t-test (Control vs Noise) – ROI: New_Noise\n",
      "   t = 3.7815, p = 0.0007\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import pandas as pd\n",
    "\n",
    "rois = [\"Left\", \"Right\", \"Back\", \"Front\", \"Noise\", \"Speech\", \"Common\", \"OnlyNoise\", \"OnlySpeech\", \"New_Speech\", \"New_Noise\"]\n",
    "\n",
    "for roi in rois:\n",
    "    df_roi_subset = df_roi[df_roi[\"ROI\"] == roi]\n",
    "\n",
    "    # Get subsets for each condition and chroma\n",
    "    df_control = df_roi_subset[(df_roi_subset[\"Condition\"] == \"Control\") & (df_roi_subset[\"Chroma\"] == \"hbo\")]\n",
    "    df_noise   = df_roi_subset[(df_roi_subset[\"Condition\"] == \"Noise\") & (df_roi_subset[\"Chroma\"] == \"hbo\")]\n",
    "    df_speech  = df_roi_subset[(df_roi_subset[\"Condition\"] == \"Speech\") & (df_roi_subset[\"Chroma\"] == \"hbo\")]\n",
    "\n",
    "    # --- Control vs Speech ---\n",
    "    control_speech = pd.merge(\n",
    "        df_control, df_speech,\n",
    "        on=[\"Subject\", \"session\"],\n",
    "        suffixes=(\"_control\", \"_speech\")\n",
    "    )\n",
    "    if not control_speech.empty:\n",
    "        t_stat_cs, p_val_cs = ttest_rel(control_speech[\"theta_control\"], control_speech[\"theta_speech\"])\n",
    "        print(f\"🔹 Paired t-test (Control vs Speech) – ROI: {roi}\")\n",
    "        print(f\"   t = {t_stat_cs:.4f}, p = {p_val_cs:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️  No matching data for Control vs Speech in ROI: {roi}\")\n",
    "\n",
    "    # --- Control vs Noise ---\n",
    "    control_noise = pd.merge(\n",
    "        df_control, df_noise,\n",
    "        on=[\"Subject\", \"session\"],\n",
    "        suffixes=(\"_control\", \"_noise\")\n",
    "    )\n",
    "    if not control_noise.empty:\n",
    "        t_stat_cn, p_val_cn = ttest_rel(control_noise[\"theta_control\"], control_noise[\"theta_noise\"])\n",
    "        print(f\"🔹 Paired t-test (Control vs Noise) – ROI: {roi}\")\n",
    "        print(f\"   t = {t_stat_cn:.4f}, p = {p_val_cn:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️  No matching data for Control vs Noise in ROI: {roi}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
